{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118608e2-d3fe-4ce0-a864-83c810910b7e",
   "metadata": {},
   "source": [
    "## Lesson 16\n",
    "# Combination of Scikit Learn and Tensorflow/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07b44f82-25b4-4bde-8b93-c41eafa4b5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import sklearn, io, os, random, cv2, json\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "from datetime import datetime\n",
    "\n",
    "## Just for using in colap\n",
    "# from google.colab import files, drive\n",
    "\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, MaxPool2D, Dense, Flatten, InputLayer,\\\n",
    "    BatchNormalization, Input, Dropout, RandomFlip, RandomContrast, RandomRotation, Resizing, Rescaling\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback, CSVLogger, EarlyStopping, \\\n",
    "    LearningRateScheduler, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ad17680-5ac6-4326-b6e3-b808a7264710",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Jus for colab\n",
    "#drive.mount('/content/drive')\n",
    "#print(\"Google Drive Mounter Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dddfd6fd-e26d-4913-a853-b1c4b4cc2992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Experiment directory\n",
    "\n",
    "experiment_name = f\"malaria_detection_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "experiment_dir = f\"./experiments/{experiment_name}\"\n",
    "\n",
    "\n",
    "def log_metrics(metrics_dict, step=None):\n",
    "    timestamp = datetime.now().isoformat()\n",
    "    log_entry={\n",
    "        'timestamp': timestamp,\n",
    "        'step': step,\n",
    "        **metrics_dict\n",
    "    }\n",
    "\n",
    "    # Append logs\n",
    "    log_file = os.path.join(experiment_dir, \"metrics.json1\")\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(json.dumps(log_entry) + \"\\n\")\n",
    "    print(f\"Step {step}: {metrics_dict}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c5d561-35db-44c7-b4f2-5a750da89c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
